\section{Methods}

We plan to extend the method of \cite{zhao2011large} to deep convolutional
neural networks. We hope to show that by using soft labels, our model can
achieve better classification performance. Additionally, we would like to
show that it can learn using smaller amounts of annotated training data.
Finally, we plan to compare different schemes for obtaining the soft labels.
Mainly, we hope to look at different linguistic semantic similarity measures
and compare them with visual similarity measures.



\subsection{Linguistic Semantic Similarity}


\subsubsection{WordNet}

WordNet is a large hierarchical database of English words that relates each
word semantically with all other words \cite{miller1995wordnet}. Word
relationships might include things like ``is a'' and ``part of'' semantics
\cite{marszalek2007semantic}.

Using the distance metric in equation \ref{eq:wordnet_dist}, we will follow the
work of \cite{fergus2010semantic} and \cite{zhao2011large} to define soft
labels for a deep CNN classifier. We will experimentally test a wide variety of
hyperparameters and values for $\kappa$.
%We will compare our relative performance gains to those of \cite{zhao2011large}
%as well as to the overall performance of pre-trained state-of-the-art models.


\subsubsection{Word2Vec}

Word2Vec is ... ? \cite{mikolov2013distributed}.

We will ... ?



\subsection{Visual Similarity}

Visual
