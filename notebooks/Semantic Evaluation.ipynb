{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "You must specify:\n",
    "\n",
    "- Which models to evaluate\n",
    "- Which test set to evaluate on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r probs_0\n",
    "%store -r probs_16\n",
    "\n",
    "models = {'w2v': probs_16.argmax(axis=1),\n",
    "          '1hot': probs_0.argmax(axis=1)\n",
    "}\n",
    "\n",
    "img_loader_str = '5_1-train_100.p'\n",
    "\n",
    "import pickle\n",
    "\n",
    "img_loader_color = pickle.load(open('pickle_jar/{}'.format(img_loader_str), 'rb'))\n",
    "\n",
    "labels = img_loader_color.test_labels.argmax(axis=1)\n",
    "\n",
    "evaluation_metrics = ['aff_wordnet_path',\n",
    "                      'aff_wordnet_wup',\n",
    "                      'aff_wordnet_zhao',\n",
    "                      'aff_gist_100',\n",
    "                      'aff_gist_100_clean',\n",
    "                      'aff_gist_1260',\n",
    "                      'aff_gist_1260_clean',\n",
    "                      'aff_w2v_1.0.p',\n",
    "                      'aff_w2v_0.5.p',\n",
    "                      'aff_w2v_0.25.p']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Evaluation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aff_wordnet_path</th>\n",
       "      <th>aff_wordnet_wup</th>\n",
       "      <th>aff_wordnet_zhao</th>\n",
       "      <th>aff_gist_100</th>\n",
       "      <th>aff_gist_100_clean</th>\n",
       "      <th>aff_gist_1260</th>\n",
       "      <th>aff_gist_1260_clean</th>\n",
       "      <th>aff_w2v_1.0.p</th>\n",
       "      <th>aff_w2v_0.5.p</th>\n",
       "      <th>aff_w2v_0.25.p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w2v</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1hot</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      aff_wordnet_path  aff_wordnet_wup  aff_wordnet_zhao  aff_gist_100  \\\n",
       "w2v                  0                0                 0             0   \n",
       "1hot                 0                0                 0             0   \n",
       "\n",
       "      aff_gist_100_clean  aff_gist_1260  aff_gist_1260_clean  aff_w2v_1.0.p  \\\n",
       "w2v                    0              0                    0              0   \n",
       "1hot                   0              0                    0              0   \n",
       "\n",
       "      aff_w2v_0.5.p  aff_w2v_0.25.p  \n",
       "w2v               0               0  \n",
       "1hot              0               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.zeros([len(models), len(evaluation_metrics)]), index=models, columns=evaluation_metrics)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in Evaluation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from soft_labels import get_soft_labels_from_file\n",
    "\n",
    "def evaluate(aff_mat, preds):\n",
    "    \"\"\"Compute the soft accuracy for predictions on the affinity matrix provided\"\"\"\n",
    "    \n",
    "    return np.mean([aff_mat[label][pred] for pred, label in zip(preds, labels)])\n",
    "\n",
    "def evaluate_all(models, evaluation_metrics):\n",
    "    \"\"\"Evaluate each model on all the evaluation metrics\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models : dict from model name to predictions\n",
    "    evaluation_metrics : list of evaluation metric to evaluate on\n",
    "    \n",
    "    - Model names are irrelevant\n",
    "    - Evaluation metrics *must* be the name of an affinity matrix in data_files\n",
    "    - Hardcode in class set 5_1 for now\n",
    "    \n",
    "    \"\"\"\n",
    "    for model_name, preds in models.items():\n",
    "        for evaluation_metric in evaluation_metrics:\n",
    "            # Load evaluation matrix\n",
    "            #\n",
    "            if evaluation_metric.endswith('.p'):\n",
    "                aff_mat = pickle.load(open('data_files/5_1/{}'.format(evaluation_metric, 'rb')))\n",
    "            else:\n",
    "                aff_mat = get_soft_labels_from_file('data_files/5_1/{}'.format(evaluation_metric))\n",
    "\n",
    "            df.ix[model_name, evaluation_metric] = evaluate(aff_mat, preds)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aff_wordnet_path</th>\n",
       "      <th>aff_wordnet_wup</th>\n",
       "      <th>aff_wordnet_zhao</th>\n",
       "      <th>aff_gist_100</th>\n",
       "      <th>aff_gist_100_clean</th>\n",
       "      <th>aff_gist_1260</th>\n",
       "      <th>aff_gist_1260_clean</th>\n",
       "      <th>aff_w2v_1.0.p</th>\n",
       "      <th>aff_w2v_0.5.p</th>\n",
       "      <th>aff_w2v_0.25.p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w2v</th>\n",
       "      <td>0.624362</td>\n",
       "      <td>0.755722</td>\n",
       "      <td>0.742397</td>\n",
       "      <td>0.983540</td>\n",
       "      <td>0.702970</td>\n",
       "      <td>0.984362</td>\n",
       "      <td>0.708035</td>\n",
       "      <td>0.741076</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.627769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1hot</th>\n",
       "      <td>0.622404</td>\n",
       "      <td>0.748340</td>\n",
       "      <td>0.735746</td>\n",
       "      <td>0.983558</td>\n",
       "      <td>0.702357</td>\n",
       "      <td>0.984631</td>\n",
       "      <td>0.711471</td>\n",
       "      <td>0.687699</td>\n",
       "      <td>0.638849</td>\n",
       "      <td>0.614425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      aff_wordnet_path  aff_wordnet_wup  aff_wordnet_zhao  aff_gist_100  \\\n",
       "w2v           0.624362         0.755722          0.742397      0.983540   \n",
       "1hot          0.622404         0.748340          0.735746      0.983558   \n",
       "\n",
       "      aff_gist_100_clean  aff_gist_1260  aff_gist_1260_clean  aff_w2v_1.0.p  \\\n",
       "w2v             0.702970       0.984362             0.708035       0.741076   \n",
       "1hot            0.702357       0.984631             0.711471       0.687699   \n",
       "\n",
       "      aff_w2v_0.5.p  aff_w2v_0.25.p  \n",
       "w2v        0.665538        0.627769  \n",
       "1hot       0.638849        0.614425  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_all(models, evaluation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Examples Which Were Missclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aff_wordnet_path</th>\n",
       "      <th>aff_wordnet_wup</th>\n",
       "      <th>aff_wordnet_zhao</th>\n",
       "      <th>aff_gist_100</th>\n",
       "      <th>aff_gist_100_clean</th>\n",
       "      <th>aff_gist_1260</th>\n",
       "      <th>aff_gist_1260_clean</th>\n",
       "      <th>aff_w2v_1.0.p</th>\n",
       "      <th>aff_w2v_0.5.p</th>\n",
       "      <th>aff_w2v_0.25.p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w2v</th>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.595440</td>\n",
       "      <td>0.550523</td>\n",
       "      <td>0.952458</td>\n",
       "      <td>0.384760</td>\n",
       "      <td>0.953228</td>\n",
       "      <td>0.383950</td>\n",
       "      <td>0.506900</td>\n",
       "      <td>0.375401</td>\n",
       "      <td>0.309652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1hot</th>\n",
       "      <td>0.361664</td>\n",
       "      <td>0.566278</td>\n",
       "      <td>0.533101</td>\n",
       "      <td>0.955525</td>\n",
       "      <td>0.432775</td>\n",
       "      <td>0.958236</td>\n",
       "      <td>0.438576</td>\n",
       "      <td>0.460857</td>\n",
       "      <td>0.388965</td>\n",
       "      <td>0.353019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      aff_wordnet_path  aff_wordnet_wup  aff_wordnet_zhao  aff_gist_100  \\\n",
       "w2v           0.299500         0.595440          0.550523      0.952458   \n",
       "1hot          0.361664         0.566278          0.533101      0.955525   \n",
       "\n",
       "      aff_gist_100_clean  aff_gist_1260  aff_gist_1260_clean  aff_w2v_1.0.p  \\\n",
       "w2v             0.384760       0.953228             0.383950       0.506900   \n",
       "1hot            0.432775       0.958236             0.438576       0.460857   \n",
       "\n",
       "      aff_w2v_0.5.p  aff_w2v_0.25.p  \n",
       "w2v        0.375401        0.309652  \n",
       "1hot       0.388965        0.353019  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_models = {model_name: preds[preds != labels] for model_name, preds in models.items()}\n",
    "\n",
    "df_missed = df.copy()\n",
    "\n",
    "evaluate_all(missed_models, evaluation_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
