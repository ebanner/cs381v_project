Experiment parameters:
   exp_group = 5_1_soft_wn, exp_id = 1
   Data file (image data): pickle_jar/5_1-1260.p
   nb_epoch = 50, batch_size = 32, model_name = "vgg16"
   Using affinity matrix: data_files/5_1/aff_wordnet_zhao
      soft_label_decay_factor = 1.0
   Validating every 1 epochs.
   Weights are NOT being saved.
   Weights are NOT being loaded.
Loading pickled data...
Done in 1.27 minutes.
Loading affinity matrix for soft labels from text file...
[[ 1.          0.5         0.14285715  0.42857143  0.42857143]
 [ 0.5         1.          0.14285715  0.42857143  0.42857143]
 [ 0.14285715  0.14285715  1.          0.2         0.22222222]
 [ 0.42857143  0.42857143  0.2         1.          0.69999999]
 [ 0.42857143  0.42857143  0.22222222  0.69999999  1.        ]]
Re-scaled soft labels.
[[ 1.          0.60653067  0.42437285  0.56471813  0.56471813]
 [ 0.60653067  1.          0.42437285  0.56471813  0.56471813]
 [ 0.42437285  0.42437285  1.          0.44932896  0.45942581]
 [ 0.56471813  0.56471813  0.44932896  1.          0.7408182 ]
 [ 0.56471813  0.56471813  0.45942581  0.7408182   1.        ]]
Building model...
Building "vgg16" model.
--------------------------------------------------------------------------------
Initial input shape: (None, 3, 224, 224)
--------------------------------------------------------------------------------
Layer (name)                  Output Shape                  Param #             
--------------------------------------------------------------------------------
ZeroPadding2D (zeropadding2d) (None, 3, 226, 226)           0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          1792                
ZeroPadding2D (zeropadding2d) (None, 64, 226, 226)          0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          36928               
MaxPooling2D (maxpooling2d)   (None, 64, 112, 112)          0                   
ZeroPadding2D (zeropadding2d) (None, 64, 114, 114)          0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         73856               
ZeroPadding2D (zeropadding2d) (None, 128, 114, 114)         0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         147584              
MaxPooling2D (maxpooling2d)   (None, 128, 56, 56)           0                   
ZeroPadding2D (zeropadding2d) (None, 128, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           295168              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
MaxPooling2D (maxpooling2d)   (None, 256, 28, 28)           0                   
ZeroPadding2D (zeropadding2d) (None, 256, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           1180160             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 14, 14)           0                   
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 7, 7)             0                   
Flatten (flatten)             (None, 25088)                 0                   
Dense (dense)                 (None, 4096)                  102764544           
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 4096)                  16781312            
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 5)                     20485               
--------------------------------------------------------------------------------
Total params: 134281029
--------------------------------------------------------------------------------
Done in 26.49 seconds.
Training model...
Epoch 1/50
100/100 [==============================] - 2s
val loss: 5.05056762695
acc: 0.33
510s - loss: 5.0614
Epoch 2/50
100/100 [==============================] - 2s
val loss: 5.04963779449
acc: 0.37
511s - loss: 5.0569
Epoch 3/50
100/100 [==============================] - 2s
val loss: 5.04911327362
acc: 0.4
511s - loss: 5.0562
Epoch 4/50
100/100 [==============================] - 2s
val loss: 5.04867982864
acc: 0.38
511s - loss: 5.0553
Epoch 5/50
100/100 [==============================] - 2s
val loss: 5.04842710495
acc: 0.41
511s - loss: 5.0555
Epoch 6/50
100/100 [==============================] - 2s
val loss: 5.04822635651
acc: 0.42
511s - loss: 5.0546
Epoch 7/50
100/100 [==============================] - 2s
val loss: 5.04804849625
acc: 0.4
511s - loss: 5.0549
Epoch 8/50
100/100 [==============================] - 2s
val loss: 5.04787921906
acc: 0.41
511s - loss: 5.0550
Epoch 9/50
100/100 [==============================] - 2s
val loss: 5.04773616791
acc: 0.42
511s - loss: 5.0549
Epoch 10/50
100/100 [==============================] - 2s
val loss: 5.04759502411
acc: 0.43
511s - loss: 5.0540
Epoch 11/50
100/100 [==============================] - 2s
val loss: 5.04747867584
acc: 0.43
512s - loss: 5.0543
Epoch 12/50
100/100 [==============================] - 2s
val loss: 5.04735708237
acc: 0.43
511s - loss: 5.0536
Epoch 13/50
100/100 [==============================] - 2s
val loss: 5.04724597931
acc: 0.42
511s - loss: 5.0538
Epoch 14/50
100/100 [==============================] - 2s
val loss: 5.04715681076
acc: 0.42
511s - loss: 5.0537
Epoch 15/50
100/100 [==============================] - 2s
val loss: 5.04707813263
acc: 0.42
511s - loss: 5.0537
Epoch 16/50
100/100 [==============================] - 2s
val loss: 5.04698944092
acc: 0.43
511s - loss: 5.0540
Epoch 17/50
100/100 [==============================] - 2s
val loss: 5.04690551758
acc: 0.43
511s - loss: 5.0537
Epoch 18/50
100/100 [==============================] - 2s
val loss: 5.04684305191
acc: 0.44
511s - loss: 5.0535
Epoch 19/50
100/100 [==============================] - 2s
val loss: 5.04677009583
acc: 0.43
511s - loss: 5.0533
Epoch 20/50
100/100 [==============================] - 2s
val loss: 5.04669284821
acc: 0.43
511s - loss: 5.0530
Epoch 21/50
100/100 [==============================] - 2s
val loss: 5.04662418365
acc: 0.44
511s - loss: 5.0528
Epoch 22/50
100/100 [==============================] - 2s
val loss: 5.04655313492
acc: 0.44
511s - loss: 5.0538
Epoch 23/50
100/100 [==============================] - 2s
val loss: 5.04649209976
acc: 0.44
511s - loss: 5.0529
Epoch 24/50
100/100 [==============================] - 2s
val loss: 5.0464348793
acc: 0.44
511s - loss: 5.0535
Epoch 25/50
100/100 [==============================] - 2s
val loss: 5.04638147354
acc: 0.44
511s - loss: 5.0532
Epoch 26/50
100/100 [==============================] - 2s
val loss: 5.04632997513
acc: 0.45
511s - loss: 5.0535
Epoch 27/50
100/100 [==============================] - 2s
val loss: 5.04628944397
acc: 0.45
511s - loss: 5.0531
Epoch 28/50
100/100 [==============================] - 2s
val loss: 5.04624319077
acc: 0.45
511s - loss: 5.0530
Epoch 29/50
100/100 [==============================] - 2s
val loss: 5.0461974144
acc: 0.45
511s - loss: 5.0534
Epoch 30/50
100/100 [==============================] - 2s
val loss: 5.04614543915
acc: 0.45
511s - loss: 5.0523
Epoch 31/50
100/100 [==============================] - 2s
val loss: 5.04609584808
acc: 0.45
511s - loss: 5.0528
Epoch 32/50
100/100 [==============================] - 2s
val loss: 5.04605531693
acc: 0.45
511s - loss: 5.0529
Epoch 33/50
100/100 [==============================] - 2s
val loss: 5.04601860046
acc: 0.45
511s - loss: 5.0530
Epoch 34/50
100/100 [==============================] - 2s
val loss: 5.04597663879
acc: 0.44
511s - loss: 5.0525
Epoch 35/50
100/100 [==============================] - 2s
val loss: 5.04593992233
acc: 0.44
511s - loss: 5.0526
Epoch 36/50
100/100 [==============================] - 2s
val loss: 5.04590463638
acc: 0.45
511s - loss: 5.0530
Epoch 37/50
100/100 [==============================] - 2s
val loss: 5.04586648941
acc: 0.46
511s - loss: 5.0523
Epoch 38/50
100/100 [==============================] - 2s
val loss: 5.04583406448
acc: 0.46
511s - loss: 5.0528
Epoch 39/50
100/100 [==============================] - 2s
val loss: 5.04580211639
acc: 0.46
511s - loss: 5.0526
Epoch 40/50
100/100 [==============================] - 2s
val loss: 5.04576921463
acc: 0.46
511s - loss: 5.0521
Epoch 41/50
100/100 [==============================] - 2s
val loss: 5.0457367897
acc: 0.46
511s - loss: 5.0527
Epoch 42/50
100/100 [==============================] - 2s
val loss: 5.04570484161
acc: 0.46
511s - loss: 5.0525
Epoch 43/50
100/100 [==============================] - 2s
val loss: 5.04567813873
acc: 0.46
511s - loss: 5.0528
Epoch 44/50
100/100 [==============================] - 2s
val loss: 5.0456495285
acc: 0.46
511s - loss: 5.0522
Epoch 45/50
100/100 [==============================] - 2s
val loss: 5.04562282562
acc: 0.46
511s - loss: 5.0531
Epoch 46/50
100/100 [==============================] - 2s
val loss: 5.04559326172
acc: 0.46
511s - loss: 5.0521
Epoch 47/50
100/100 [==============================] - 2s
val loss: 5.04556894302
acc: 0.46
511s - loss: 5.0528
Epoch 48/50
100/100 [==============================] - 2s
val loss: 5.04554176331
acc: 0.46
511s - loss: 5.0523
Epoch 49/50
100/100 [==============================] - 2s
val loss: 5.04551649094
acc: 0.46
511s - loss: 5.0526
Epoch 50/50
100/100 [==============================] - 2s
val loss: 5.04549360275
acc: 0.46
511s - loss: 5.0526
Done in 7.11 hours.
