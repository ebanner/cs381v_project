Experiment parameters:
   exp_group = 5_1_soft_wn, exp_id = 6
   Data file (image data): pickle_jar/5_1-100.p
   nb_epoch = 50, batch_size = 32, model_name = "vgg16"
   Using affinity matrix: data_files/5_1/aff_wordnet_wup
      soft_label_decay_factor = 3.0
   Validating every 1 epochs.
   Weights are NOT being saved.
   Weights are NOT being loaded.
Loading pickled data...
Done in 6.64 seconds.
Loading affinity matrix for soft labels from text file...
[[ 1.          0.5         0.17391305  0.5         0.52173913]
 [ 0.5         1.          0.17391305  0.5         0.52173913]
 [ 0.17391305  0.17391305  1.          0.21052632  0.22222222]
 [ 0.5         0.5         0.21052632  1.          0.7368421 ]
 [ 0.52173913  0.52173913  0.22222222  0.7368421   1.        ]]
[[ 0.46512148  0.15217435  0.07343286  0.15217435  0.15974902]
 [ 0.15217435  0.46512148  0.07343286  0.15217435  0.15974902]
 [ 0.08091461  0.08091461  0.81255239  0.08962502  0.09260047]
 [ 0.14061257  0.14061257  0.07708545  0.39712909  0.22993864]
 [ 0.14526084  0.14526084  0.07855716  0.22587718  0.38763949]]
Building model...
Building "vgg16" model.
--------------------------------------------------------------------------------
Initial input shape: (None, 3, 224, 224)
--------------------------------------------------------------------------------
Layer (name)                  Output Shape                  Param #             
--------------------------------------------------------------------------------
ZeroPadding2D (zeropadding2d) (None, 3, 226, 226)           0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          1792                
ZeroPadding2D (zeropadding2d) (None, 64, 226, 226)          0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          36928               
MaxPooling2D (maxpooling2d)   (None, 64, 112, 112)          0                   
ZeroPadding2D (zeropadding2d) (None, 64, 114, 114)          0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         73856               
ZeroPadding2D (zeropadding2d) (None, 128, 114, 114)         0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         147584              
MaxPooling2D (maxpooling2d)   (None, 128, 56, 56)           0                   
ZeroPadding2D (zeropadding2d) (None, 128, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           295168              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
MaxPooling2D (maxpooling2d)   (None, 256, 28, 28)           0                   
ZeroPadding2D (zeropadding2d) (None, 256, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           1180160             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 14, 14)           0                   
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 7, 7)             0                   
Flatten (flatten)             (None, 25088)                 0                   
Dense (dense)                 (None, 4096)                  102764544           
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 4096)                  16781312            
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 5)                     20485               
--------------------------------------------------------------------------------
Total params: 134281029
--------------------------------------------------------------------------------
Done in 26.93 seconds.
Training model...
Epoch 1/50
100/100 [==============================] - 2s
val loss: 1.65116262436
acc: 0.2
45s - loss: 1.6716
Epoch 2/50
100/100 [==============================] - 2s
val loss: 1.64824426174
acc: 0.24
45s - loss: 1.6567
Epoch 3/50
100/100 [==============================] - 2s
val loss: 1.64735686779
acc: 0.23
45s - loss: 1.6525
Epoch 4/50
100/100 [==============================] - 2s
val loss: 1.64683008194
acc: 0.25
45s - loss: 1.6508
Epoch 5/50
100/100 [==============================] - 2s
val loss: 1.6463946104
acc: 0.25
45s - loss: 1.6500
Epoch 6/50
100/100 [==============================] - 2s
val loss: 1.64608490467
acc: 0.25
45s - loss: 1.6468
Epoch 7/50
100/100 [==============================] - 2s
val loss: 1.64571654797
acc: 0.28
45s - loss: 1.6475
Epoch 8/50
100/100 [==============================] - 2s
val loss: 1.64544260502
acc: 0.29
45s - loss: 1.6492
Epoch 9/50
100/100 [==============================] - 2s
val loss: 1.64523613453
acc: 0.29
45s - loss: 1.6451
Epoch 10/50
100/100 [==============================] - 2s
val loss: 1.64497244358
acc: 0.3
45s - loss: 1.6491
Epoch 11/50
100/100 [==============================] - 2s
val loss: 1.64480316639
acc: 0.29
45s - loss: 1.6490
Epoch 12/50
100/100 [==============================] - 2s
val loss: 1.64468193054
acc: 0.29
45s - loss: 1.6487
Epoch 13/50
100/100 [==============================] - 2s
val loss: 1.64453554153
acc: 0.29
45s - loss: 1.6479
Epoch 14/50
100/100 [==============================] - 2s
val loss: 1.64437663555
acc: 0.31
45s - loss: 1.6461
Epoch 15/50
100/100 [==============================] - 2s
val loss: 1.64421021938
acc: 0.31
45s - loss: 1.6474
Epoch 16/50
100/100 [==============================] - 2s
val loss: 1.644079566
acc: 0.31
45s - loss: 1.6432
Epoch 17/50
100/100 [==============================] - 2s
val loss: 1.64392328262
acc: 0.31
45s - loss: 1.6467
Epoch 18/50
100/100 [==============================] - 2s
val loss: 1.64379060268
acc: 0.31
45s - loss: 1.6469
Epoch 19/50
100/100 [==============================] - 2s
val loss: 1.64368963242
acc: 0.31
45s - loss: 1.6466
Epoch 20/50
100/100 [==============================] - 2s
val loss: 1.64361214638
acc: 0.31
45s - loss: 1.6438
Epoch 21/50
100/100 [==============================] - 2s
val loss: 1.64350426197
acc: 0.31
45s - loss: 1.6456
Epoch 22/50
100/100 [==============================] - 2s
val loss: 1.64339506626
acc: 0.31
45s - loss: 1.6443
Epoch 23/50
100/100 [==============================] - 2s
val loss: 1.64328014851
acc: 0.31
45s - loss: 1.6455
Epoch 24/50
100/100 [==============================] - 2s
val loss: 1.64317810535
acc: 0.3
45s - loss: 1.6452
Epoch 25/50
100/100 [==============================] - 2s
val loss: 1.64308416843
acc: 0.31
45s - loss: 1.6442
Epoch 26/50
100/100 [==============================] - 2s
val loss: 1.64300203323
acc: 0.3
45s - loss: 1.6434
Epoch 27/50
100/100 [==============================] - 2s
val loss: 1.64294612408
acc: 0.3
45s - loss: 1.6440
Epoch 28/50
100/100 [==============================] - 2s
val loss: 1.64288115501
acc: 0.3
45s - loss: 1.6446
Epoch 29/50
100/100 [==============================] - 2s
val loss: 1.64280509949
acc: 0.3
45s - loss: 1.6433
Epoch 30/50
100/100 [==============================] - 2s
val loss: 1.6427282095
acc: 0.3
45s - loss: 1.6425
Epoch 31/50
100/100 [==============================] - 2s
val loss: 1.64265072346
acc: 0.29
45s - loss: 1.6425
Epoch 32/50
100/100 [==============================] - 2s
val loss: 1.6425909996
acc: 0.3
45s - loss: 1.6452
Epoch 33/50
100/100 [==============================] - 2s
val loss: 1.64252591133
acc: 0.3
45s - loss: 1.6462
Epoch 34/50
100/100 [==============================] - 2s
val loss: 1.64245605469
acc: 0.3
45s - loss: 1.6412
Epoch 35/50
100/100 [==============================] - 2s
val loss: 1.64239025116
acc: 0.3
45s - loss: 1.6456
Epoch 36/50
100/100 [==============================] - 2s
val loss: 1.64232754707
acc: 0.3
45s - loss: 1.6416
Epoch 37/50
100/100 [==============================] - 2s
val loss: 1.64227259159
acc: 0.3
45s - loss: 1.6459
Epoch 38/50
100/100 [==============================] - 2s
val loss: 1.64223814011
acc: 0.29
45s - loss: 1.6464
Epoch 39/50
100/100 [==============================] - 2s
val loss: 1.64219629765
acc: 0.29
45s - loss: 1.6425
Epoch 40/50
100/100 [==============================] - 2s
val loss: 1.64215302467
acc: 0.29
45s - loss: 1.6429
Epoch 41/50
100/100 [==============================] - 2s
val loss: 1.64211499691
acc: 0.29
45s - loss: 1.6468
Epoch 42/50
100/100 [==============================] - 2s
val loss: 1.64207196236
acc: 0.3
45s - loss: 1.6415
Epoch 43/50
100/100 [==============================] - 2s
val loss: 1.64201641083
acc: 0.3
45s - loss: 1.6439
Epoch 44/50
100/100 [==============================] - 2s
val loss: 1.6419686079
acc: 0.29
45s - loss: 1.6434
Epoch 45/50
100/100 [==============================] - 2s
val loss: 1.64191401005
acc: 0.3
45s - loss: 1.6428
Epoch 46/50
100/100 [==============================] - 2s
val loss: 1.64187347889
acc: 0.29
45s - loss: 1.6487
Epoch 47/50
100/100 [==============================] - 2s
val loss: 1.6418337822
acc: 0.29
45s - loss: 1.6428
Epoch 48/50
100/100 [==============================] - 2s
val loss: 1.6417952776
acc: 0.29
45s - loss: 1.6430
Epoch 49/50
100/100 [==============================] - 2s
val loss: 1.64175415039
acc: 0.29
45s - loss: 1.6418
Epoch 50/50
100/100 [==============================] - 2s
val loss: 1.64171993732
acc: 0.29
45s - loss: 1.6453
Done in 38.12 minutes.
