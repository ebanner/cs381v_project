Experiment parameters:
   exp_group = 5_1_soft_wn, exp_id = 21
   Data file (image data): pickle_jar/5_1-1260.p
   nb_epoch = 50, batch_size = 32, model_name = "vgg16"
   Using affinity matrix: data_files/5_1/aff_wordnet_path
      soft_label_decay_factor = 1.0
   Validating every 1 epochs.
   Weights are NOT being saved.
   Weights are NOT being loaded.
Loading pickled data...
Done in 1.27 minutes.
Loading affinity matrix for soft labels from text file...
[[ 1.          0.06666667  0.05        0.07692308  0.08333334]
 [ 0.06666667  1.          0.05        0.07692308  0.08333334]
 [ 0.05        0.05        1.          0.0625      0.06666667]
 [ 0.07692308  0.07692308  0.0625      1.          0.16666667]
 [ 0.08333334  0.08333334  0.06666667  0.16666667  1.        ]]
Re-scaled soft labels.
[[ 1.          0.39324072  0.38674104  0.3972947   0.39984965]
 [ 0.39324072  1.          0.38674104  0.3972947   0.39984965]
 [ 0.38674104  0.38674104  1.          0.39160562  0.39324072]
 [ 0.3972947   0.3972947   0.39160562  1.          0.43459821]
 [ 0.39984965  0.39984965  0.39324072  0.43459821  1.        ]]
Building model...
Building "vgg16" model.
--------------------------------------------------------------------------------
Initial input shape: (None, 3, 224, 224)
--------------------------------------------------------------------------------
Layer (name)                  Output Shape                  Param #             
--------------------------------------------------------------------------------
ZeroPadding2D (zeropadding2d) (None, 3, 226, 226)           0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          1792                
ZeroPadding2D (zeropadding2d) (None, 64, 226, 226)          0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          36928               
MaxPooling2D (maxpooling2d)   (None, 64, 112, 112)          0                   
ZeroPadding2D (zeropadding2d) (None, 64, 114, 114)          0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         73856               
ZeroPadding2D (zeropadding2d) (None, 128, 114, 114)         0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         147584              
MaxPooling2D (maxpooling2d)   (None, 128, 56, 56)           0                   
ZeroPadding2D (zeropadding2d) (None, 128, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           295168              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
MaxPooling2D (maxpooling2d)   (None, 256, 28, 28)           0                   
ZeroPadding2D (zeropadding2d) (None, 256, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           1180160             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 14, 14)           0                   
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 7, 7)             0                   
Flatten (flatten)             (None, 25088)                 0                   
Dense (dense)                 (None, 4096)                  102764544           
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 4096)                  16781312            
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 5)                     20485               
--------------------------------------------------------------------------------
Total params: 134281029
--------------------------------------------------------------------------------
Done in 26.34 seconds.
Training model...
Epoch 1/50
100/100 [==============================] - 2s
val loss: 4.15857791901
acc: 0.43
508s - loss: 4.1726
Epoch 2/50
100/100 [==============================] - 2s
val loss: 4.15534353256
acc: 0.46
510s - loss: 4.1644
Epoch 3/50
100/100 [==============================] - 2s
val loss: 4.15340805054
acc: 0.47
510s - loss: 4.1625
Epoch 4/50
100/100 [==============================] - 2s
val loss: 4.1521024704
acc: 0.48
510s - loss: 4.1612
Epoch 5/50
100/100 [==============================] - 2s
val loss: 4.15101099014
acc: 0.5
510s - loss: 4.1605
Epoch 6/50
100/100 [==============================] - 2s
val loss: 4.15019512177
acc: 0.49
510s - loss: 4.1595
Epoch 7/50
100/100 [==============================] - 2s
val loss: 4.1494846344
acc: 0.5
510s - loss: 4.1596
Epoch 8/50
100/100 [==============================] - 2s
val loss: 4.14883136749
acc: 0.5
510s - loss: 4.1585
Epoch 9/50
100/100 [==============================] - 2s
val loss: 4.14829349518
acc: 0.5
510s - loss: 4.1578
Epoch 10/50
100/100 [==============================] - 2s
val loss: 4.14776659012
acc: 0.5
510s - loss: 4.1579
Epoch 11/50
100/100 [==============================] - 2s
val loss: 4.14724349976
acc: 0.51
510s - loss: 4.1570
Epoch 12/50
100/100 [==============================] - 2s
val loss: 4.14691400528
acc: 0.5
510s - loss: 4.1587
Epoch 13/50
100/100 [==============================] - 2s
val loss: 4.14656686783
acc: 0.5
510s - loss: 4.1575
Epoch 14/50
100/100 [==============================] - 2s
val loss: 4.14623689651
acc: 0.5
510s - loss: 4.1566
Epoch 15/50
100/100 [==============================] - 2s
val loss: 4.14593791962
acc: 0.5
510s - loss: 4.1574
Epoch 16/50
100/100 [==============================] - 2s
val loss: 4.14564466476
acc: 0.5
510s - loss: 4.1566
Epoch 17/50
100/100 [==============================] - 2s
val loss: 4.14535331726
acc: 0.5
510s - loss: 4.1566
Epoch 18/50
100/100 [==============================] - 2s
val loss: 4.14508581161
acc: 0.5
510s - loss: 4.1566
Epoch 19/50
100/100 [==============================] - 2s
val loss: 4.14480161667
acc: 0.5
510s - loss: 4.1551
Epoch 20/50
100/100 [==============================] - 2s
val loss: 4.14452505112
acc: 0.51
510s - loss: 4.1549
Epoch 21/50
100/100 [==============================] - 2s
val loss: 4.14427709579
acc: 0.51
510s - loss: 4.1551
Epoch 22/50
100/100 [==============================] - 2s
val loss: 4.14405059814
acc: 0.51
510s - loss: 4.1557
Epoch 23/50
100/100 [==============================] - 2s
val loss: 4.14383602142
acc: 0.51
510s - loss: 4.1545
Epoch 24/50
100/100 [==============================] - 2s
val loss: 4.1436457634
acc: 0.51
510s - loss: 4.1551
Epoch 25/50
100/100 [==============================] - 2s
val loss: 4.14346647263
acc: 0.51
510s - loss: 4.1545
Epoch 26/50
100/100 [==============================] - 2s
val loss: 4.1432723999
acc: 0.51
510s - loss: 4.1552
Epoch 27/50
100/100 [==============================] - 2s
val loss: 4.14309024811
acc: 0.51
510s - loss: 4.1545
Epoch 28/50
100/100 [==============================] - 2s
val loss: 4.14291334152
acc: 0.51
510s - loss: 4.1535
Epoch 29/50
100/100 [==============================] - 2s
val loss: 4.14275789261
acc: 0.51
510s - loss: 4.1536
Epoch 30/50
100/100 [==============================] - 2s
val loss: 4.14260435104
acc: 0.51
510s - loss: 4.1551
Epoch 31/50
100/100 [==============================] - 2s
val loss: 4.1424612999
acc: 0.51
510s - loss: 4.1539
Epoch 32/50
100/100 [==============================] - 2s
val loss: 4.14231109619
acc: 0.51
510s - loss: 4.1539
Epoch 33/50
100/100 [==============================] - 2s
val loss: 4.14216852188
acc: 0.51
510s - loss: 4.1538
Epoch 34/50
100/100 [==============================] - 2s
val loss: 4.14204216003
acc: 0.51
510s - loss: 4.1538
Epoch 35/50
100/100 [==============================] - 2s
val loss: 4.14190006256
acc: 0.51
510s - loss: 4.1542
Epoch 36/50
100/100 [==============================] - 2s
val loss: 4.14178562164
acc: 0.51
510s - loss: 4.1535
Epoch 37/50
100/100 [==============================] - 2s
val loss: 4.14166021347
acc: 0.51
510s - loss: 4.1523
Epoch 38/50
100/100 [==============================] - 2s
val loss: 4.14153671265
acc: 0.51
510s - loss: 4.1536
Epoch 39/50
100/100 [==============================] - 2s
val loss: 4.14142084122
acc: 0.51
510s - loss: 4.1535
Epoch 40/50
100/100 [==============================] - 2s
val loss: 4.14129972458
acc: 0.51
510s - loss: 4.1529
Epoch 41/50
100/100 [==============================] - 2s
val loss: 4.14118766785
acc: 0.51
510s - loss: 4.1534
Epoch 42/50
100/100 [==============================] - 2s
val loss: 4.14106845856
acc: 0.51
510s - loss: 4.1529
Epoch 43/50
100/100 [==============================] - 2s
val loss: 4.14097118378
acc: 0.51
510s - loss: 4.1531
Epoch 44/50
100/100 [==============================] - 2s
val loss: 4.14087152481
acc: 0.51
510s - loss: 4.1527
Epoch 45/50
100/100 [==============================] - 2s
val loss: 4.14076280594
acc: 0.51
510s - loss: 4.1531
Epoch 46/50
100/100 [==============================] - 2s
val loss: 4.14065647125
acc: 0.51
510s - loss: 4.1523
Epoch 47/50
100/100 [==============================] - 2s
val loss: 4.14056158066
acc: 0.51
510s - loss: 4.1531
Epoch 48/50
100/100 [==============================] - 2s
val loss: 4.14045763016
acc: 0.51
510s - loss: 4.1520
Epoch 49/50
100/100 [==============================] - 2s
val loss: 4.14037227631
acc: 0.51
510s - loss: 4.1526
Epoch 50/50
100/100 [==============================] - 2s
val loss: 4.1402797699
acc: 0.51
510s - loss: 4.1528
Done in 7.09 hours.
