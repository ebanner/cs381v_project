Experiment parameters:
   exp_group = 10_1_soft_wn, exp_id = 6
   Data file (image data): pickle_jar/10_1-100.p
   nb_epoch = 50, batch_size = 32, model_name = "vgg16"
   Using affinity matrix: data_files/10_1/aff_wordnet_zhao
      soft_label_decay_factor = 9.0
   Validating every 1 epochs.
   Weights are NOT being saved.
   Weights are NOT being loaded.
Loading pickled data...
Done in 13.42 seconds.
Loading affinity matrix for soft labels from text file...
[[ 1.          0.5         0.5         0.14285715  0.33333334  0.14285715
   0.42857143  0.42857143  0.27777779  0.35714287]
 [ 0.5         1.          0.5         0.14285715  0.33333334  0.14285715
   0.42857143  0.42857143  0.27777779  0.35714287]
 [ 0.5         0.5         1.          0.14285715  0.33333334  0.25
   0.54545456  0.54545456  0.27777779  0.45454547]
 [ 0.14285715  0.14285715  0.14285715  1.          0.13333334  0.21428572
   0.14285715  0.14285715  0.11111111  0.14285715]
 [ 0.33333334  0.33333334  0.33333334  0.13333334  1.          0.13333334
   0.33333334  0.33333334  0.72222221  0.46666667]
 [ 0.14285715  0.14285715  0.25        0.21428572  0.13333334  1.          0.2
   0.22222222  0.11111111  0.25      ]
 [ 0.42857143  0.42857143  0.54545456  0.14285715  0.33333334  0.2         1.
   0.69999999  0.27777779  0.45454547]
 [ 0.42857143  0.42857143  0.54545456  0.14285715  0.33333334  0.22222222
   0.69999999  1.          0.27777779  0.45454547]
 [ 0.27777779  0.27777779  0.27777779  0.11111111  0.72222221  0.11111111
   0.27777779  0.27777779  1.          0.3888889 ]
 [ 0.35714287  0.35714287  0.45454547  0.14285715  0.46666667  0.25
   0.45454547  0.45454547  0.3888889   1.        ]]
Re-scaled soft labels.
[[  1.00000000e+00   1.11089963e-02   1.11089963e-02   4.46404156e-04
    2.47875345e-03   4.46404156e-04   5.84098045e-03   5.84098045e-03
    1.50343915e-03   3.07111628e-03]
 [  1.11089963e-02   1.00000000e+00   1.11089963e-02   4.46404156e-04
    2.47875345e-03   4.46404156e-04   5.84098045e-03   5.84098045e-03
    1.50343915e-03   3.07111628e-03]
 [  1.11089963e-02   1.11089963e-02   1.00000000e+00   4.46404156e-04
    2.47875345e-03   1.17087958e-03   1.67240240e-02   1.67240240e-02
    1.50343915e-03   7.37919658e-03]
 [  4.46404156e-04   4.46404156e-04   4.46404156e-04   1.00000000e+00
    4.09734901e-04   8.49019561e-04   4.46404156e-04   4.46404156e-04
    3.35462624e-04   4.46404156e-04]
 [  2.47875345e-03   2.47875345e-03   2.47875345e-03   4.09734901e-04
    1.00000000e+00   4.09734901e-04   2.47875345e-03   2.47875345e-03
    8.20849985e-02   8.22974928e-03]
 [  4.46404156e-04   4.46404156e-04   1.17087958e-03   8.49019561e-04
    4.09734901e-04   1.00000000e+00   7.46585603e-04   9.11881973e-04
    3.35462624e-04   1.17087958e-03]
 [  5.84098045e-03   5.84098045e-03   1.67240240e-02   4.46404156e-04
    2.47875345e-03   7.46585603e-04   1.00000000e+00   6.72055110e-02
    1.50343915e-03   7.37919658e-03]
 [  5.84098045e-03   5.84098045e-03   1.67240240e-02   4.46404156e-04
    2.47875345e-03   9.11881973e-04   6.72055110e-02   1.00000000e+00
    1.50343915e-03   7.37919658e-03]
 [  1.50343915e-03   1.50343915e-03   1.50343915e-03   3.35462624e-04
    8.20849985e-02   3.35462624e-04   1.50343915e-03   1.50343915e-03
    1.00000000e+00   4.08677151e-03]
 [  3.07111628e-03   3.07111628e-03   7.37919658e-03   4.46404156e-04
    8.22974928e-03   1.17087958e-03   7.37919658e-03   7.37919658e-03
    4.08677151e-03   1.00000000e+00]]
Building model...
Building "vgg16" model.
--------------------------------------------------------------------------------
Initial input shape: (None, 3, 224, 224)
--------------------------------------------------------------------------------
Layer (name)                  Output Shape                  Param #             
--------------------------------------------------------------------------------
ZeroPadding2D (zeropadding2d) (None, 3, 226, 226)           0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          1792                
ZeroPadding2D (zeropadding2d) (None, 64, 226, 226)          0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          36928               
MaxPooling2D (maxpooling2d)   (None, 64, 112, 112)          0                   
ZeroPadding2D (zeropadding2d) (None, 64, 114, 114)          0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         73856               
ZeroPadding2D (zeropadding2d) (None, 128, 114, 114)         0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         147584              
MaxPooling2D (maxpooling2d)   (None, 128, 56, 56)           0                   
ZeroPadding2D (zeropadding2d) (None, 128, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           295168              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
MaxPooling2D (maxpooling2d)   (None, 256, 28, 28)           0                   
ZeroPadding2D (zeropadding2d) (None, 256, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           1180160             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 14, 14)           0                   
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 7, 7)             0                   
Flatten (flatten)             (None, 25088)                 0                   
Dense (dense)                 (None, 4096)                  102764544           
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 4096)                  16781312            
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 10)                    40970               
--------------------------------------------------------------------------------
Total params: 134301514
--------------------------------------------------------------------------------
Done in 44.03 seconds.
Training model...
Epoch 1/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.4347485733
acc: 0.125
88s - loss: 2.4631
Epoch 2/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.42885002136
acc: 0.135
88s - loss: 2.4383
Epoch 3/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.42632629395
acc: 0.145
88s - loss: 2.4329
Epoch 4/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.42470368385
acc: 0.15
88s - loss: 2.4354
Epoch 5/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.42308094025
acc: 0.16
88s - loss: 2.4259
Epoch 6/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.42151762962
acc: 0.18
88s - loss: 2.4306
Epoch 7/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.42015003204
acc: 0.175
88s - loss: 2.4208
Epoch 8/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.41909858704
acc: 0.175
88s - loss: 2.4300
Epoch 9/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.41808232307
acc: 0.175
88s - loss: 2.4157
Epoch 10/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.41664426804
acc: 0.18
88s - loss: 2.4202
Epoch 11/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.41536273956
acc: 0.19
88s - loss: 2.4221
Epoch 12/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.4146568203
acc: 0.185
88s - loss: 2.4225
Epoch 13/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.41378565788
acc: 0.185
88s - loss: 2.4235
Epoch 14/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.41316484451
acc: 0.185
88s - loss: 2.4217
Epoch 15/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.41213646889
acc: 0.185
88s - loss: 2.4102
Epoch 16/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.41133718491
acc: 0.19
88s - loss: 2.4178
Epoch 17/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.41054394722
acc: 0.185
88s - loss: 2.4113
Epoch 18/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40976229668
acc: 0.18
88s - loss: 2.4036
Epoch 19/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40912402153
acc: 0.19
88s - loss: 2.4112
Epoch 20/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40845564842
acc: 0.185
88s - loss: 2.4172
Epoch 21/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40793614388
acc: 0.18
88s - loss: 2.4158
Epoch 22/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40709240913
acc: 0.19
88s - loss: 2.4059
Epoch 23/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40665330887
acc: 0.19
88s - loss: 2.4198
Epoch 24/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40624962807
acc: 0.19
88s - loss: 2.4196
Epoch 25/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40572348595
acc: 0.19
88s - loss: 2.4130
Epoch 26/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40510982513
acc: 0.19
88s - loss: 2.4113
Epoch 27/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.404724617
acc: 0.195
88s - loss: 2.4158
Epoch 28/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40421872139
acc: 0.195
88s - loss: 2.4048
Epoch 29/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.4036485672
acc: 0.195
88s - loss: 2.4137
Epoch 30/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40317347527
acc: 0.195
88s - loss: 2.4154
Epoch 31/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40264419556
acc: 0.195
88s - loss: 2.4085
Epoch 32/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40225161552
acc: 0.205
88s - loss: 2.4084
Epoch 33/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40180623055
acc: 0.195
88s - loss: 2.4076
Epoch 34/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40134111404
acc: 0.195
88s - loss: 2.4064
Epoch 35/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.4009823513
acc: 0.2
88s - loss: 2.4077
Epoch 36/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40075178146
acc: 0.2
88s - loss: 2.4120
Epoch 37/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.40037109375
acc: 0.19
88s - loss: 2.4100
Epoch 38/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39986662865
acc: 0.195
88s - loss: 2.4086
Epoch 39/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39951160431
acc: 0.19
88s - loss: 2.4056
Epoch 40/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39926959038
acc: 0.2
88s - loss: 2.4082
Epoch 41/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39899742126
acc: 0.2
88s - loss: 2.4066
Epoch 42/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39859235764
acc: 0.2
88s - loss: 2.3958
Epoch 43/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39818831444
acc: 0.2
88s - loss: 2.4056
Epoch 44/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39766841888
acc: 0.205
88s - loss: 2.4028
Epoch 45/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39728837967
acc: 0.195
88s - loss: 2.4090
Epoch 46/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39684120178
acc: 0.195
88s - loss: 2.4025
Epoch 47/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39647559166
acc: 0.195
88s - loss: 2.4047
Epoch 48/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39597701073
acc: 0.195
88s - loss: 2.3988
Epoch 49/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39573941231
acc: 0.195
88s - loss: 2.4088
Epoch 50/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39552013397
acc: 0.2
88s - loss: 2.4072
Done in 1.23 hours.
