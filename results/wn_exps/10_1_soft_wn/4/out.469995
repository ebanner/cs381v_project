Experiment parameters:
   exp_group = 10_1_soft_wn, exp_id = 4
   Data file (image data): pickle_jar/10_1-100.p
   nb_epoch = 50, batch_size = 32, model_name = "vgg16"
   Using affinity matrix: data_files/10_1/aff_wordnet_zhao
      soft_label_decay_factor = 7.0
   Validating every 1 epochs.
   Weights are NOT being saved.
   Weights are NOT being loaded.
Loading pickled data...
Done in 13.56 seconds.
Loading affinity matrix for soft labels from text file...
[[ 1.          0.5         0.5         0.14285715  0.33333334  0.14285715
   0.42857143  0.42857143  0.27777779  0.35714287]
 [ 0.5         1.          0.5         0.14285715  0.33333334  0.14285715
   0.42857143  0.42857143  0.27777779  0.35714287]
 [ 0.5         0.5         1.          0.14285715  0.33333334  0.25
   0.54545456  0.54545456  0.27777779  0.45454547]
 [ 0.14285715  0.14285715  0.14285715  1.          0.13333334  0.21428572
   0.14285715  0.14285715  0.11111111  0.14285715]
 [ 0.33333334  0.33333334  0.33333334  0.13333334  1.          0.13333334
   0.33333334  0.33333334  0.72222221  0.46666667]
 [ 0.14285715  0.14285715  0.25        0.21428572  0.13333334  1.          0.2
   0.22222222  0.11111111  0.25      ]
 [ 0.42857143  0.42857143  0.54545456  0.14285715  0.33333334  0.2         1.
   0.69999999  0.27777779  0.45454547]
 [ 0.42857143  0.42857143  0.54545456  0.14285715  0.33333334  0.22222222
   0.69999999  1.          0.27777779  0.45454547]
 [ 0.27777779  0.27777779  0.27777779  0.11111111  0.72222221  0.11111111
   0.27777779  0.27777779  1.          0.3888889 ]
 [ 0.35714287  0.35714287  0.45454547  0.14285715  0.46666667  0.25
   0.45454547  0.45454547  0.3888889   1.        ]]
Re-scaled soft labels.
[[ 1.          0.03019738  0.03019738  0.00247875  0.00940356  0.00247875
   0.01831564  0.01831564  0.00637383  0.011109  ]
 [ 0.03019738  1.          0.03019738  0.00247875  0.00940356  0.00247875
   0.01831564  0.01831564  0.00637383  0.011109  ]
 [ 0.03019738  0.03019738  1.          0.00247875  0.00940356  0.00524752
   0.04151012  0.04151012  0.00637383  0.02196771]
 [ 0.00247875  0.00247875  0.00247875  1.          0.00231889  0.00408677
   0.00247875  0.00247875  0.00198483  0.00247875]
 [ 0.00940356  0.00940356  0.00940356  0.00231889  1.          0.00231889
   0.00940356  0.00940356  0.14306667  0.023913  ]
 [ 0.00247875  0.00247875  0.00524752  0.00408677  0.00231889  1.
   0.00369786  0.00432024  0.00198483  0.00524752]
 [ 0.01831564  0.01831564  0.04151012  0.00247875  0.00940356  0.00369786
   1.          0.12245641  0.00637383  0.02196771]
 [ 0.01831564  0.01831564  0.04151012  0.00247875  0.00940356  0.00432024
   0.12245641  1.          0.00637383  0.02196771]
 [ 0.00637383  0.00637383  0.00637383  0.00198483  0.14306667  0.00198483
   0.00637383  0.00637383  1.          0.01387346]
 [ 0.011109    0.011109    0.02196771  0.00247875  0.023913    0.00524752
   0.02196771  0.02196771  0.01387346  1.        ]]
Building model...
Building "vgg16" model.
--------------------------------------------------------------------------------
Initial input shape: (None, 3, 224, 224)
--------------------------------------------------------------------------------
Layer (name)                  Output Shape                  Param #             
--------------------------------------------------------------------------------
ZeroPadding2D (zeropadding2d) (None, 3, 226, 226)           0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          1792                
ZeroPadding2D (zeropadding2d) (None, 64, 226, 226)          0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          36928               
MaxPooling2D (maxpooling2d)   (None, 64, 112, 112)          0                   
ZeroPadding2D (zeropadding2d) (None, 64, 114, 114)          0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         73856               
ZeroPadding2D (zeropadding2d) (None, 128, 114, 114)         0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         147584              
MaxPooling2D (maxpooling2d)   (None, 128, 56, 56)           0                   
ZeroPadding2D (zeropadding2d) (None, 128, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           295168              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
MaxPooling2D (maxpooling2d)   (None, 256, 28, 28)           0                   
ZeroPadding2D (zeropadding2d) (None, 256, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           1180160             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 14, 14)           0                   
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 7, 7)             0                   
Flatten (flatten)             (None, 25088)                 0                   
Dense (dense)                 (None, 4096)                  102764544           
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 4096)                  16781312            
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 10)                    40970               
--------------------------------------------------------------------------------
Total params: 134301514
--------------------------------------------------------------------------------
Done in 27.15 seconds.
Training model...
Epoch 1/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.64647372246
acc: 0.105
89s - loss: 2.6684
Epoch 2/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.63961744308
acc: 0.17
89s - loss: 2.6579
Epoch 3/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.63669817924
acc: 0.175
89s - loss: 2.6465
Epoch 4/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.63348938942
acc: 0.215
89s - loss: 2.6447
Epoch 5/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.63039048195
acc: 0.19
89s - loss: 2.6390
Epoch 6/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.62761695862
acc: 0.215
89s - loss: 2.6314
Epoch 7/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.62505587578
acc: 0.225
89s - loss: 2.6255
Epoch 8/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.62307389259
acc: 0.23
89s - loss: 2.6364
Epoch 9/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.62118468285
acc: 0.22
89s - loss: 2.6285
Epoch 10/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.61934420586
acc: 0.245
89s - loss: 2.6242
Epoch 11/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.61764836311
acc: 0.245
89s - loss: 2.6240
Epoch 12/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.616484375
acc: 0.24
89s - loss: 2.6250
Epoch 13/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.61498894691
acc: 0.23
89s - loss: 2.6210
Epoch 14/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.61362855911
acc: 0.23
89s - loss: 2.6197
Epoch 15/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.61223449707
acc: 0.225
89s - loss: 2.6214
Epoch 16/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.61089609146
acc: 0.225
89s - loss: 2.6229
Epoch 17/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.60987628937
acc: 0.235
89s - loss: 2.6234
Epoch 18/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.60886539459
acc: 0.26
89s - loss: 2.6209
Epoch 19/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.60765925407
acc: 0.26
89s - loss: 2.6198
Epoch 20/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.60638936043
acc: 0.27
89s - loss: 2.6112
Epoch 21/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.60509917259
acc: 0.285
89s - loss: 2.6137
Epoch 22/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.60378755569
acc: 0.28
89s - loss: 2.6098
Epoch 23/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.60277439117
acc: 0.285
89s - loss: 2.6152
Epoch 24/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.60148609161
acc: 0.285
89s - loss: 2.5995
Epoch 25/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.60045948982
acc: 0.295
89s - loss: 2.6112
Epoch 26/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.59945309639
acc: 0.29
89s - loss: 2.6018
Epoch 27/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.59848391533
acc: 0.28
89s - loss: 2.6080
Epoch 28/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.59752705574
acc: 0.28
89s - loss: 2.6136
Epoch 29/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.59659501076
acc: 0.285
89s - loss: 2.6028
Epoch 30/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.59580657959
acc: 0.285
89s - loss: 2.6101
Epoch 31/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.59493619919
acc: 0.28
89s - loss: 2.6073
Epoch 32/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.59419220924
acc: 0.28
89s - loss: 2.6048
Epoch 33/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.59308994293
acc: 0.275
89s - loss: 2.5929
Epoch 34/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.59211011887
acc: 0.29
89s - loss: 2.5992
Epoch 35/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.59121006012
acc: 0.29
89s - loss: 2.6048
Epoch 36/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.59042377472
acc: 0.29
89s - loss: 2.6083
Epoch 37/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58950558662
acc: 0.28
89s - loss: 2.5962
Epoch 38/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58860707283
acc: 0.295
89s - loss: 2.5978
Epoch 39/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58760447502
acc: 0.29
89s - loss: 2.5911
Epoch 40/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58685304642
acc: 0.295
89s - loss: 2.5975
Epoch 41/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58607897758
acc: 0.295
89s - loss: 2.5997
Epoch 42/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58539509773
acc: 0.295
89s - loss: 2.6031
Epoch 43/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58454772949
acc: 0.295
89s - loss: 2.5919
Epoch 44/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58370960236
acc: 0.295
89s - loss: 2.5955
Epoch 45/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58297724724
acc: 0.29
89s - loss: 2.5973
Epoch 46/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58216077805
acc: 0.295
89s - loss: 2.5970
Epoch 47/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58130843163
acc: 0.305
89s - loss: 2.5919
Epoch 48/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.58049710274
acc: 0.305
89s - loss: 2.5913
Epoch 49/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.57976730347
acc: 0.3
89s - loss: 2.5879
Epoch 50/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.5789312458
acc: 0.3
89s - loss: 2.5867
Done in 1.25 hours.
