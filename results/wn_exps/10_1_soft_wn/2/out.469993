Experiment parameters:
   exp_group = 10_1_soft_wn, exp_id = 2
   Data file (image data): pickle_jar/10_1-100.p
   nb_epoch = 50, batch_size = 32, model_name = "vgg16"
   Using affinity matrix: data_files/10_1/aff_wordnet_zhao
      soft_label_decay_factor = 5.0
   Validating every 1 epochs.
   Weights are NOT being saved.
   Weights are NOT being loaded.
Loading pickled data...
Done in 13.45 seconds.
Loading affinity matrix for soft labels from text file...
[[ 1.          0.5         0.5         0.14285715  0.33333334  0.14285715
   0.42857143  0.42857143  0.27777779  0.35714287]
 [ 0.5         1.          0.5         0.14285715  0.33333334  0.14285715
   0.42857143  0.42857143  0.27777779  0.35714287]
 [ 0.5         0.5         1.          0.14285715  0.33333334  0.25
   0.54545456  0.54545456  0.27777779  0.45454547]
 [ 0.14285715  0.14285715  0.14285715  1.          0.13333334  0.21428572
   0.14285715  0.14285715  0.11111111  0.14285715]
 [ 0.33333334  0.33333334  0.33333334  0.13333334  1.          0.13333334
   0.33333334  0.33333334  0.72222221  0.46666667]
 [ 0.14285715  0.14285715  0.25        0.21428572  0.13333334  1.          0.2
   0.22222222  0.11111111  0.25      ]
 [ 0.42857143  0.42857143  0.54545456  0.14285715  0.33333334  0.2         1.
   0.69999999  0.27777779  0.45454547]
 [ 0.42857143  0.42857143  0.54545456  0.14285715  0.33333334  0.22222222
   0.69999999  1.          0.27777779  0.45454547]
 [ 0.27777779  0.27777779  0.27777779  0.11111111  0.72222221  0.11111111
   0.27777779  0.27777779  1.          0.3888889 ]
 [ 0.35714287  0.35714287  0.45454547  0.14285715  0.46666667  0.25
   0.45454547  0.45454547  0.3888889   1.        ]]
Re-scaled soft labels.
[[ 1.          0.082085    0.082085    0.01376379  0.03567401  0.01376379
   0.05743263  0.05743263  0.0270218   0.04018403]
 [ 0.082085    1.          0.082085    0.01376379  0.03567401  0.01376379
   0.05743263  0.05743263  0.0270218   0.04018403]
 [ 0.082085    0.082085    1.          0.01376379  0.03567401  0.02351775
   0.10303081  0.10303081  0.0270218   0.06539742]
 [ 0.01376379  0.01376379  0.01376379  1.          0.01312373  0.01967176
   0.01376379  0.01376379  0.01174363  0.01376379]
 [ 0.03567401  0.03567401  0.03567401  0.01312373  1.          0.01312373
   0.03567401  0.03567401  0.24935219  0.06948346]
 [ 0.01376379  0.01376379  0.02351775  0.01967176  0.01312373  1.
   0.01831564  0.02046808  0.01174363  0.02351775]
 [ 0.05743263  0.05743263  0.10303081  0.01376379  0.03567401  0.01831564
   1.          0.22313017  0.0270218   0.06539742]
 [ 0.05743263  0.05743263  0.10303081  0.01376379  0.03567401  0.02046808
   0.22313017  1.          0.0270218   0.06539742]
 [ 0.0270218   0.0270218   0.0270218   0.01174363  0.24935219  0.01174363
   0.0270218   0.0270218   1.          0.04709655]
 [ 0.04018403  0.04018403  0.06539742  0.01376379  0.06948346  0.02351775
   0.06539742  0.06539742  0.04709655  1.        ]]
Building model...
Building "vgg16" model.
--------------------------------------------------------------------------------
Initial input shape: (None, 3, 224, 224)
--------------------------------------------------------------------------------
Layer (name)                  Output Shape                  Param #             
--------------------------------------------------------------------------------
ZeroPadding2D (zeropadding2d) (None, 3, 226, 226)           0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          1792                
ZeroPadding2D (zeropadding2d) (None, 64, 226, 226)          0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          36928               
MaxPooling2D (maxpooling2d)   (None, 64, 112, 112)          0                   
ZeroPadding2D (zeropadding2d) (None, 64, 114, 114)          0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         73856               
ZeroPadding2D (zeropadding2d) (None, 128, 114, 114)         0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         147584              
MaxPooling2D (maxpooling2d)   (None, 128, 56, 56)           0                   
ZeroPadding2D (zeropadding2d) (None, 128, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           295168              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
MaxPooling2D (maxpooling2d)   (None, 256, 28, 28)           0                   
ZeroPadding2D (zeropadding2d) (None, 256, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           1180160             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 14, 14)           0                   
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 7, 7)             0                   
Flatten (flatten)             (None, 25088)                 0                   
Dense (dense)                 (None, 4096)                  102764544           
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 4096)                  16781312            
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 10)                    40970               
--------------------------------------------------------------------------------
Total params: 134301514
--------------------------------------------------------------------------------
Done in 26.53 seconds.
Training model...
Epoch 1/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.26698914528
acc: 0.08
88s - loss: 3.3045
Epoch 2/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.26096819878
acc: 0.145
88s - loss: 3.2786
Epoch 3/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.25746687889
acc: 0.175
88s - loss: 3.2643
Epoch 4/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.25532580376
acc: 0.185
88s - loss: 3.2676
Epoch 5/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.25324215889
acc: 0.195
88s - loss: 3.2594
Epoch 6/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.2517141819
acc: 0.205
88s - loss: 3.2588
Epoch 7/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.25052630424
acc: 0.205
88s - loss: 3.2643
Epoch 8/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.24902911186
acc: 0.225
88s - loss: 3.2575
Epoch 9/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.24766827583
acc: 0.22
88s - loss: 3.2580
Epoch 10/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.24653271675
acc: 0.22
88s - loss: 3.2547
Epoch 11/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.24556477547
acc: 0.22
88s - loss: 3.2524
Epoch 12/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.24458681107
acc: 0.24
88s - loss: 3.2427
Epoch 13/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.24379396439
acc: 0.225
88s - loss: 3.2525
Epoch 14/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.24304898262
acc: 0.23
88s - loss: 3.2491
Epoch 15/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.24204090118
acc: 0.23
88s - loss: 3.2457
Epoch 16/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.24132510185
acc: 0.245
88s - loss: 3.2500
Epoch 17/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.24050521851
acc: 0.25
88s - loss: 3.2541
Epoch 18/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23971378326
acc: 0.245
88s - loss: 3.2451
Epoch 19/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23908714294
acc: 0.255
88s - loss: 3.2459
Epoch 20/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23853760719
acc: 0.25
88s - loss: 3.2528
Epoch 21/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23795959473
acc: 0.255
88s - loss: 3.2459
Epoch 22/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23743084908
acc: 0.25
88s - loss: 3.2476
Epoch 23/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23690094948
acc: 0.255
88s - loss: 3.2466
Epoch 24/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23643045425
acc: 0.25
88s - loss: 3.2500
Epoch 25/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23588856697
acc: 0.25
88s - loss: 3.2471
Epoch 26/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23530932426
acc: 0.255
88s - loss: 3.2456
Epoch 27/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.2345844841
acc: 0.255
88s - loss: 3.2438
Epoch 28/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23404352188
acc: 0.26
88s - loss: 3.2429
Epoch 29/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23338484764
acc: 0.255
88s - loss: 3.2368
Epoch 30/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23283541679
acc: 0.265
88s - loss: 3.2372
Epoch 31/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23230009079
acc: 0.27
88s - loss: 3.2403
Epoch 32/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23173830986
acc: 0.27
88s - loss: 3.2400
Epoch 33/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23123873711
acc: 0.265
88s - loss: 3.2410
Epoch 34/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.23077760696
acc: 0.265
88s - loss: 3.2401
Epoch 35/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.2302132988
acc: 0.26
88s - loss: 3.2352
Epoch 36/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22969099998
acc: 0.27
88s - loss: 3.2374
Epoch 37/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22922732353
acc: 0.26
88s - loss: 3.2338
Epoch 38/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22895122528
acc: 0.255
88s - loss: 3.2409
Epoch 39/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22856372833
acc: 0.25
88s - loss: 3.2373
Epoch 40/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22803879738
acc: 0.26
88s - loss: 3.2329
Epoch 41/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22757496834
acc: 0.26
88s - loss: 3.2357
Epoch 42/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22711397171
acc: 0.265
88s - loss: 3.2363
Epoch 43/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22676476479
acc: 0.26
88s - loss: 3.2397
Epoch 44/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.2262775898
acc: 0.27
88s - loss: 3.2333
Epoch 45/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.2258067131
acc: 0.265
88s - loss: 3.2374
Epoch 46/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22549079895
acc: 0.27
88s - loss: 3.2452
Epoch 47/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22516387939
acc: 0.275
88s - loss: 3.2343
Epoch 48/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22472698212
acc: 0.28
88s - loss: 3.2303
Epoch 49/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.2244015789
acc: 0.285
88s - loss: 3.2337
Epoch 50/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 3.22396160126
acc: 0.29
88s - loss: 3.2346
Done in 1.23 hours.
