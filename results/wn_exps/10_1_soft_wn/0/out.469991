Experiment parameters:
   exp_group = 10_1_soft_wn, exp_id = 0
   Data file (image data): pickle_jar/10_1-100.p
   nb_epoch = 50, batch_size = 32, model_name = "vgg16"
   Using affinity matrix: data_files/10_1/aff_wordnet_zhao
      soft_label_decay_factor = 3.0
   Validating every 1 epochs.
   Weights are NOT being saved.
   Weights are NOT being loaded.
Loading pickled data...
Done in 13.46 seconds.
Loading affinity matrix for soft labels from text file...
[[ 1.          0.5         0.5         0.14285715  0.33333334  0.14285715
   0.42857143  0.42857143  0.27777779  0.35714287]
 [ 0.5         1.          0.5         0.14285715  0.33333334  0.14285715
   0.42857143  0.42857143  0.27777779  0.35714287]
 [ 0.5         0.5         1.          0.14285715  0.33333334  0.25
   0.54545456  0.54545456  0.27777779  0.45454547]
 [ 0.14285715  0.14285715  0.14285715  1.          0.13333334  0.21428572
   0.14285715  0.14285715  0.11111111  0.14285715]
 [ 0.33333334  0.33333334  0.33333334  0.13333334  1.          0.13333334
   0.33333334  0.33333334  0.72222221  0.46666667]
 [ 0.14285715  0.14285715  0.25        0.21428572  0.13333334  1.          0.2
   0.22222222  0.11111111  0.25      ]
 [ 0.42857143  0.42857143  0.54545456  0.14285715  0.33333334  0.2         1.
   0.69999999  0.27777779  0.45454547]
 [ 0.42857143  0.42857143  0.54545456  0.14285715  0.33333334  0.22222222
   0.69999999  1.          0.27777779  0.45454547]
 [ 0.27777779  0.27777779  0.27777779  0.11111111  0.72222221  0.11111111
   0.27777779  0.27777779  1.          0.3888889 ]
 [ 0.35714287  0.35714287  0.45454547  0.14285715  0.46666667  0.25
   0.45454547  0.45454547  0.3888889   1.        ]]
Re-scaled soft labels.
[[ 1.          0.22313017  0.22313017  0.07642629  0.1353353   0.07642629
   0.18009233  0.18009233  0.11455886  0.1453557 ]
 [ 0.22313017  1.          0.22313017  0.07642629  0.1353353   0.07642629
   0.18009233  0.18009233  0.11455886  0.1453557 ]
 [ 0.22313017  0.22313017  1.          0.07642629  0.1353353   0.10539922
   0.2557292   0.2557292   0.11455886  0.19468674]
 [ 0.07642629  0.07642629  0.07642629  1.          0.07427359  0.09469038
   0.07642629  0.07642629  0.06948344  0.07642629]
 [ 0.1353353   0.1353353   0.1353353   0.07427359  1.          0.07427359
   0.1353353   0.1353353   0.43459818  0.20189653]
 [ 0.07642629  0.07642629  0.10539922  0.09469038  0.07427359  1.
   0.09071794  0.09697195  0.06948344  0.10539922]
 [ 0.18009233  0.18009233  0.2557292   0.07642629  0.1353353   0.09071794
   1.          0.40656966  0.11455886  0.19468674]
 [ 0.18009233  0.18009233  0.2557292   0.07642629  0.1353353   0.09697195
   0.40656966  1.          0.11455886  0.19468674]
 [ 0.11455886  0.11455886  0.11455886  0.06948344  0.43459818  0.06948344
   0.11455886  0.11455886  1.          0.15987976]
 [ 0.1453557   0.1453557   0.19468674  0.07642629  0.20189653  0.10539922
   0.19468674  0.19468674  0.15987976  1.        ]]
Building model...
Building "vgg16" model.
--------------------------------------------------------------------------------
Initial input shape: (None, 3, 224, 224)
--------------------------------------------------------------------------------
Layer (name)                  Output Shape                  Param #             
--------------------------------------------------------------------------------
ZeroPadding2D (zeropadding2d) (None, 3, 226, 226)           0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          1792                
ZeroPadding2D (zeropadding2d) (None, 64, 226, 226)          0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          36928               
MaxPooling2D (maxpooling2d)   (None, 64, 112, 112)          0                   
ZeroPadding2D (zeropadding2d) (None, 64, 114, 114)          0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         73856               
ZeroPadding2D (zeropadding2d) (None, 128, 114, 114)         0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         147584              
MaxPooling2D (maxpooling2d)   (None, 128, 56, 56)           0                   
ZeroPadding2D (zeropadding2d) (None, 128, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           295168              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
MaxPooling2D (maxpooling2d)   (None, 256, 28, 28)           0                   
ZeroPadding2D (zeropadding2d) (None, 256, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           1180160             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 14, 14)           0                   
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 7, 7)             0                   
Flatten (flatten)             (None, 25088)                 0                   
Dense (dense)                 (None, 4096)                  102764544           
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 4096)                  16781312            
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 10)                    40970               
--------------------------------------------------------------------------------
Total params: 134301514
--------------------------------------------------------------------------------
Done in 26.9 seconds.
Training model...
Epoch 1/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.32183193207
acc: 0.18
91s - loss: 5.3518
Epoch 2/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.31888933182
acc: 0.15
91s - loss: 5.3366
Epoch 3/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.31595880508
acc: 0.18
91s - loss: 5.3261
Epoch 4/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.31458169937
acc: 0.185
91s - loss: 5.3242
Epoch 5/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.31326692581
acc: 0.18
91s - loss: 5.3246
Epoch 6/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.3122070694
acc: 0.185
91s - loss: 5.3240
Epoch 7/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.31140140533
acc: 0.2
91s - loss: 5.3215
Epoch 8/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.31044408798
acc: 0.205
91s - loss: 5.3175
Epoch 9/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.31008916855
acc: 0.2
91s - loss: 5.3201
Epoch 10/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30937738419
acc: 0.205
91s - loss: 5.3196
Epoch 11/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30850753784
acc: 0.21
91s - loss: 5.3177
Epoch 12/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30805395126
acc: 0.22
91s - loss: 5.3201
Epoch 13/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30736070633
acc: 0.245
91s - loss: 5.3148
Epoch 14/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30687265396
acc: 0.24
91s - loss: 5.3178
Epoch 15/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30647674561
acc: 0.235
91s - loss: 5.3164
Epoch 16/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30591913223
acc: 0.24
91s - loss: 5.3182
Epoch 17/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30544565201
acc: 0.24
91s - loss: 5.3161
Epoch 18/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30500556946
acc: 0.23
91s - loss: 5.3171
Epoch 19/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30476379395
acc: 0.24
91s - loss: 5.3134
Epoch 20/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30448547363
acc: 0.24
91s - loss: 5.3140
Epoch 21/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30414617538
acc: 0.225
91s - loss: 5.3146
Epoch 22/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30377988815
acc: 0.24
91s - loss: 5.3084
Epoch 23/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30349048615
acc: 0.24
91s - loss: 5.3115
Epoch 24/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30317331314
acc: 0.245
91s - loss: 5.3103
Epoch 25/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30283823013
acc: 0.26
91s - loss: 5.3093
Epoch 26/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30247156143
acc: 0.26
91s - loss: 5.3130
Epoch 27/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30223861694
acc: 0.255
91s - loss: 5.3122
Epoch 28/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30188505173
acc: 0.255
91s - loss: 5.3118
Epoch 29/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.3016778183
acc: 0.25
91s - loss: 5.3117
Epoch 30/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30147125244
acc: 0.255
91s - loss: 5.3118
Epoch 31/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30119256973
acc: 0.255
91s - loss: 5.3148
Epoch 32/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30102209091
acc: 0.26
91s - loss: 5.3096
Epoch 33/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30067316055
acc: 0.26
91s - loss: 5.3099
Epoch 34/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30048112869
acc: 0.26
91s - loss: 5.3089
Epoch 35/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30026247025
acc: 0.255
91s - loss: 5.3114
Epoch 36/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.30003118515
acc: 0.255
91s - loss: 5.3116
Epoch 37/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29979326248
acc: 0.25
91s - loss: 5.3131
Epoch 38/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29956708908
acc: 0.255
91s - loss: 5.3107
Epoch 39/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29931814194
acc: 0.26
91s - loss: 5.3095
Epoch 40/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29916021347
acc: 0.265
91s - loss: 5.3119
Epoch 41/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29900762558
acc: 0.27
91s - loss: 5.3101
Epoch 42/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29883838654
acc: 0.265
91s - loss: 5.3127
Epoch 43/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.2986060524
acc: 0.265
91s - loss: 5.3054
Epoch 44/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29848199844
acc: 0.26
91s - loss: 5.3086
Epoch 45/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29825778961
acc: 0.26
91s - loss: 5.3061
Epoch 46/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29809230804
acc: 0.265
91s - loss: 5.3089
Epoch 47/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29784925461
acc: 0.26
91s - loss: 5.3037
Epoch 48/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29767374039
acc: 0.26
91s - loss: 5.3040
Epoch 49/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29751432419
acc: 0.26
91s - loss: 5.3120
Epoch 50/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 5.29739696503
acc: 0.26
91s - loss: 5.3109
Done in 1.27 hours.
