Experiment parameters:
   exp_group = 10_1_soft_wn, exp_id = 7
   Data file (image data): pickle_jar/10_1-1260.p
   nb_epoch = 50, batch_size = 32, model_name = "vgg16"
   Using affinity matrix: data_files/10_1/aff_wordnet_zhao
      soft_label_decay_factor = 9.0
   Validating every 1 epochs.
   Weights are NOT being saved.
   Weights are NOT being loaded.
Loading pickled data...
Done in 2.51 minutes.
Loading affinity matrix for soft labels from text file...
[[ 1.          0.5         0.5         0.14285715  0.33333334  0.14285715
   0.42857143  0.42857143  0.27777779  0.35714287]
 [ 0.5         1.          0.5         0.14285715  0.33333334  0.14285715
   0.42857143  0.42857143  0.27777779  0.35714287]
 [ 0.5         0.5         1.          0.14285715  0.33333334  0.25
   0.54545456  0.54545456  0.27777779  0.45454547]
 [ 0.14285715  0.14285715  0.14285715  1.          0.13333334  0.21428572
   0.14285715  0.14285715  0.11111111  0.14285715]
 [ 0.33333334  0.33333334  0.33333334  0.13333334  1.          0.13333334
   0.33333334  0.33333334  0.72222221  0.46666667]
 [ 0.14285715  0.14285715  0.25        0.21428572  0.13333334  1.          0.2
   0.22222222  0.11111111  0.25      ]
 [ 0.42857143  0.42857143  0.54545456  0.14285715  0.33333334  0.2         1.
   0.69999999  0.27777779  0.45454547]
 [ 0.42857143  0.42857143  0.54545456  0.14285715  0.33333334  0.22222222
   0.69999999  1.          0.27777779  0.45454547]
 [ 0.27777779  0.27777779  0.27777779  0.11111111  0.72222221  0.11111111
   0.27777779  0.27777779  1.          0.3888889 ]
 [ 0.35714287  0.35714287  0.45454547  0.14285715  0.46666667  0.25
   0.45454547  0.45454547  0.3888889   1.        ]]
Re-scaled soft labels.
[[  1.00000000e+00   1.11089963e-02   1.11089963e-02   4.46404156e-04
    2.47875345e-03   4.46404156e-04   5.84098045e-03   5.84098045e-03
    1.50343915e-03   3.07111628e-03]
 [  1.11089963e-02   1.00000000e+00   1.11089963e-02   4.46404156e-04
    2.47875345e-03   4.46404156e-04   5.84098045e-03   5.84098045e-03
    1.50343915e-03   3.07111628e-03]
 [  1.11089963e-02   1.11089963e-02   1.00000000e+00   4.46404156e-04
    2.47875345e-03   1.17087958e-03   1.67240240e-02   1.67240240e-02
    1.50343915e-03   7.37919658e-03]
 [  4.46404156e-04   4.46404156e-04   4.46404156e-04   1.00000000e+00
    4.09734901e-04   8.49019561e-04   4.46404156e-04   4.46404156e-04
    3.35462624e-04   4.46404156e-04]
 [  2.47875345e-03   2.47875345e-03   2.47875345e-03   4.09734901e-04
    1.00000000e+00   4.09734901e-04   2.47875345e-03   2.47875345e-03
    8.20849985e-02   8.22974928e-03]
 [  4.46404156e-04   4.46404156e-04   1.17087958e-03   8.49019561e-04
    4.09734901e-04   1.00000000e+00   7.46585603e-04   9.11881973e-04
    3.35462624e-04   1.17087958e-03]
 [  5.84098045e-03   5.84098045e-03   1.67240240e-02   4.46404156e-04
    2.47875345e-03   7.46585603e-04   1.00000000e+00   6.72055110e-02
    1.50343915e-03   7.37919658e-03]
 [  5.84098045e-03   5.84098045e-03   1.67240240e-02   4.46404156e-04
    2.47875345e-03   9.11881973e-04   6.72055110e-02   1.00000000e+00
    1.50343915e-03   7.37919658e-03]
 [  1.50343915e-03   1.50343915e-03   1.50343915e-03   3.35462624e-04
    8.20849985e-02   3.35462624e-04   1.50343915e-03   1.50343915e-03
    1.00000000e+00   4.08677151e-03]
 [  3.07111628e-03   3.07111628e-03   7.37919658e-03   4.46404156e-04
    8.22974928e-03   1.17087958e-03   7.37919658e-03   7.37919658e-03
    4.08677151e-03   1.00000000e+00]]
Building model...
Building "vgg16" model.
--------------------------------------------------------------------------------
Initial input shape: (None, 3, 224, 224)
--------------------------------------------------------------------------------
Layer (name)                  Output Shape                  Param #             
--------------------------------------------------------------------------------
ZeroPadding2D (zeropadding2d) (None, 3, 226, 226)           0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          1792                
ZeroPadding2D (zeropadding2d) (None, 64, 226, 226)          0                   
Convolution2D (convolution2d) (None, 64, 224, 224)          36928               
MaxPooling2D (maxpooling2d)   (None, 64, 112, 112)          0                   
ZeroPadding2D (zeropadding2d) (None, 64, 114, 114)          0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         73856               
ZeroPadding2D (zeropadding2d) (None, 128, 114, 114)         0                   
Convolution2D (convolution2d) (None, 128, 112, 112)         147584              
MaxPooling2D (maxpooling2d)   (None, 128, 56, 56)           0                   
ZeroPadding2D (zeropadding2d) (None, 128, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           295168              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
ZeroPadding2D (zeropadding2d) (None, 256, 58, 58)           0                   
Convolution2D (convolution2d) (None, 256, 56, 56)           590080              
MaxPooling2D (maxpooling2d)   (None, 256, 28, 28)           0                   
ZeroPadding2D (zeropadding2d) (None, 256, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           1180160             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 30, 30)           0                   
Convolution2D (convolution2d) (None, 512, 28, 28)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 14, 14)           0                   
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
ZeroPadding2D (zeropadding2d) (None, 512, 16, 16)           0                   
Convolution2D (convolution2d) (None, 512, 14, 14)           2359808             
MaxPooling2D (maxpooling2d)   (None, 512, 7, 7)             0                   
Flatten (flatten)             (None, 25088)                 0                   
Dense (dense)                 (None, 4096)                  102764544           
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 4096)                  16781312            
Dropout (dropout)             (None, 4096)                  0                   
Dense (dense)                 (None, 10)                    40970               
--------------------------------------------------------------------------------
Total params: 134301514
--------------------------------------------------------------------------------
Done in 26.27 seconds.
Training model...
Epoch 1/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.39572010994
acc: 0.23
1025s - loss: 2.4286
Epoch 2/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.37449433327
acc: 0.235
1026s - loss: 2.4085
Epoch 3/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.35769392967
acc: 0.26
1026s - loss: 2.3939
Epoch 4/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.34416963577
acc: 0.265
1026s - loss: 2.3860
Epoch 5/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.33189769745
acc: 0.265
1026s - loss: 2.3769
Epoch 6/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.32053829193
acc: 0.275
1026s - loss: 2.3717
Epoch 7/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.31083607674
acc: 0.29
1025s - loss: 2.3676
Epoch 8/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.30148396492
acc: 0.29
1026s - loss: 2.3580
Epoch 9/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.29291081429
acc: 0.29
1026s - loss: 2.3530
Epoch 10/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.28536686897
acc: 0.295
1025s - loss: 2.3505
Epoch 11/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.27808857918
acc: 0.305
1026s - loss: 2.3422
Epoch 12/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.27128346443
acc: 0.3
1026s - loss: 2.3400
Epoch 13/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.26496245384
acc: 0.31
1026s - loss: 2.3338
Epoch 14/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.25921422005
acc: 0.32
1025s - loss: 2.3324
Epoch 15/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.25386187553
acc: 0.32
1026s - loss: 2.3284
Epoch 16/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.24907305717
acc: 0.32
1026s - loss: 2.3269
Epoch 17/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.2447648716
acc: 0.32
1026s - loss: 2.3227
Epoch 18/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.24056292534
acc: 0.32
1025s - loss: 2.3238
Epoch 19/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.2364479351
acc: 0.32
1024s - loss: 2.3200
Epoch 20/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.23251448631
acc: 0.32
1025s - loss: 2.3137
Epoch 21/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.22924398422
acc: 0.325
1026s - loss: 2.3154
Epoch 22/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.22592577934
acc: 0.32
1026s - loss: 2.3118
Epoch 23/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.22223852158
acc: 0.32
1026s - loss: 2.3038
Epoch 24/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.21885420799
acc: 0.33
1026s - loss: 2.3039
Epoch 25/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.21551734924
acc: 0.325
1026s - loss: 2.2981
Epoch 26/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.212684021
acc: 0.325
1026s - loss: 2.3006
Epoch 27/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.21024127007
acc: 0.325
1026s - loss: 2.3040
Epoch 28/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.20778820992
acc: 0.325
1026s - loss: 2.2968
Epoch 29/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.20517717361
acc: 0.325
1026s - loss: 2.2974
Epoch 30/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.20293943405
acc: 0.325
1026s - loss: 2.2974
Epoch 31/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.20078159332
acc: 0.33
1026s - loss: 2.2960
Epoch 32/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.19834629059
acc: 0.325
1026s - loss: 2.2902
Epoch 33/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.19617359161
acc: 0.33
1026s - loss: 2.2918
Epoch 34/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.19421490669
acc: 0.33
1026s - loss: 2.2920
Epoch 35/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.19215483665
acc: 0.33
1026s - loss: 2.2857
Epoch 36/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.1902082634
acc: 0.33
1025s - loss: 2.2846
Epoch 37/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.18812350273
acc: 0.33
1025s - loss: 2.2818
Epoch 38/50
128/200 [==================>...........] - ETA: 1s200/200 [==============================] - 4s     
val loss: 2.18642595291
acc: 0.335
